<html>
<head>
    <link rel="stylesheet" href="/css/examples.css">
</head>
<body>

<h3>RCS EXAMPLES</h3>
RCS examples are provided to assist you in learning the software and the development of your applications on the <a href="http://www.bu.edu/tech/support/research/computing-resources/scc/">Shared Computing Cluster (SCC)</a>. The instructions provided along with the code assume that the underlying OS is Linux. If these examples are run on a different architecture, you might need to make some changes to the code and/or the way the program is built and executed. 
<br>

<h3>RCS Examples for Intel Xeon Phi Knights Landing (KNL)</h3>

<h4>Directory Structure</h4>

<ul>
<li><b>examples</b> - This directory presents KNL example programs. </li>
</ul>


<h4>Usage notes</h4>
</br>

Kinghts Landing (KNL) is an Intel Xeon Phi many-integrated-core (MIC)  processor.
Currently there are two KNL nodes on SCC. 
The host names are <code>scc-ib1</code> and <code>scc-ib2</code>. 
There are 68 physical cores on each KNL node. 
Each core supports 4 computing threads by the hyper-threading technique.
That says there are maximum 272 threads for multi-threading programs.

<br></br>
Different from the previous generation of Xeon Phi --- Knights Corner (KNC), the KNL is self-hosted.
That says operation systems can be installed on KNL.
The CentOS 7 system is installed on the SCC KNL nodes.
This is different from the CentOS 6 on SCC login nodes.
 
<br></br>
Intel Omni-path is installed to support data communication between the two KNL nodes.

<br></br>
Note that a single KNL core is much slower than a regular Xeon CPU core. 
To be accelerated on KNL, the programms have to be parallelized, for example by MPI, OpenMP or hybrid MPI-OpenMP. 
It is not recommended to run a serial program on KNL.

<br></br>
C or Fortran codes can be compiled and run on KNL. If the C or Fortran codes are parallelized and optimized appropriately, they can be accelerated by KNL considerbly. Intel Math Kernel Library (MKL) functions can be automatically accelerated on KNL. For Python programmers, if the numpy or scipy libraries are built with Intel MKL, the numpy or scipy functions can be automatically accelerated on KNL too.

<br></br>
Please refer to the following instructions to compile and run C or Fortran programs on the KNL nodes. 

<ul>
<li><b>Compile programs</b> </li>
</br>
It is recommended to compile programs directly on KNL nodes, so that they are best optimized.
To compile, request a single KNL core first,
<ul>
<br> <code>qrsh -l knl</code> </br>
</ul>
</br>
Then load the Intel compiler,
<ul>
<br> <code>module load intel/2016</code> </br>
</ul>
</br>
[Note: the Intel compiler provides the best optimized options for KNL.]
<br></br>
To compile an OpenMP C code,
<ul>
<br> <code>icc -openmp -O3 -xmic-avx512 name.c -o executable</code> </br>
</ul>
</br>
or an OpenMP Fortran code,
<ul>
<br> <code>ifort -openmp -O3 -xmic-avx512 name.f90 -o executable</code> </br>
</ul>
</br>
[Note: The option <code>-xmic-avx512</code> is to make use of the 512-bit vectorization on KNL. This can accelerate the program signifigcantly.]
<br></br>
To compile MPI programs, load an MPI implementation first,
<ul>
<br> <code>module use /share/module/knl</code> </br>
<code>module load openmpi/2.1.1_intel-2016_knl</code> </br>
</ul>
</br>

[Note: The openmpi/2.1.1_intel-2016_knl is the only MPI implementation working for KNL on SCC.]
<br></br>

Then compile an MPI C code,
<ul>
<br> <code>mpicc -O3 -xmic-avx512 name.c -o executable</code> </br>
</ul>
</br>
or an MPI Fortran code,
<ul>
<br> <code>mpifort -O3 -xmic-avx512 name.f90 -o executable</code> </br>
</ul>
</br>

</ul>

<ul>
<li><b>Run OpenMP programs</b> </li>
</br>
First request one KNL node by <code>qrsh</code>,

<ul>
<br> <code>qrsh -l knl -pe omp 68</code> </br>
</ul>
</br>

[Note: the "-pe omp 68" means 68 pysical cores are requested. Users can specifiy <code>OMP_NUM_THREADS=272</code> to make use of the total 272 threads.]
<br></br>

Then run the OpenMP program,
</br>

<ul>
<br><code>export OMP_NUM_THREADS=272</code></br>
<code>/path/to/executable</code> </br>
</ul>
</br>

</ul>

<ul>
<li><b>Run MPI programs</b> </li>
</br>

First request the KNL nodes by <code>qrsh</code>. For exampele, request one KNL node, 

<ul>
<br> <code>qrsh -l knl -pe mpi_68_tasks_per_node 68</code> </br>
</ul>
</br>

or two KNL nodes,

<ul>
<br> <code>qrsh -l knl -pe mpi_68_tasks_per_node 136</code> </br>
</ul>
</br>

Then load the MPI implementation, 
<ul>
<br> <code>module use /share/module/knl</code> </br>
<code>module load openmpi/2.1.1_intel-2016_knl</code> </br>
</ul>
</br>

Then run the MPI program on one KNL node,

<ul>
<br> <code>mpirun -np 68 /path/to/executable </code> </br>
</ul>
</br>

or on two KNL nodes,

<ul>
<br> <code>mpirun -np 136 /path/to/executable </code> </br>
</ul>
</br>

[Note: It is recommended to run up to 68 (other than 272) MPI tasks per node.]
<br></br>

</ul>

<ul>
<li><b>Run programs in background</b> </li>
</br>

Users can run batch jobs in the background using <code>qsub</code>,

<ul>
<br> <code>qsub script </code> </br>
</ul>
</br>

Please refer to example scripts for OpenMP or MPI programs in the <code>example</code> directory.
<br></br>

[Note: Currently the maximum runtime on the SCC KNL nodes is 24 hours.]
<br></br>

</ul>




<h4>Contact Information</h4>

Shaohao Chen: <em>shaohao@bu.edu</em><br>

<h4>Operating System Requirements</h4>

   The examples presented in this directory were written in C or Fortran.
<br>   - c or Fortran compilers available </br>
   
<h4>External References</h4>
<ul>
For more KNL examples, please refer to the
<a href="http://www.prace-ri.eu/best-practice-guide-knights-landing-january-2017">Best Practice Guide --- Knights Landing</a>.
</ul>


<!--#include virtual="/css/footer.html" -->
</body>
</html>
